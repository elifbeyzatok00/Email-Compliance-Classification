import streamlit as st
import torch
import json
from transformers import AutoTokenizer, AutoModelForSequenceClassification

# Sayfa yapÄ±landÄ±rmasÄ±
st.set_page_config(
    page_title="E-posta Uyumluluk SÄ±nÄ±flandÄ±rmasÄ±",
    page_icon="ğŸ“§"
)

@st.cache_resource
def load_model_and_tokenizer():
    """Model ve tokenizer'Ä± yÃ¼kle (cache ile performans optimizasyonu)"""
    try:
        model_path = "models/trained_model2/checkpoint-3111"
        model = AutoModelForSequenceClassification.from_pretrained(model_path)
        tokenizer = AutoTokenizer.from_pretrained(model_path)
        
        # GPU varsa kullan
        device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        model.to(device)
        
        return model, tokenizer, device
    except Exception as e:
        st.error(f"Model yÃ¼klenirken hata oluÅŸtu: {e}")
        return None, None, None

@st.cache_resource
def load_label_mapping():
    """Label mapping'ini yÃ¼kle"""
    try:
        # EÄŸitim datasÄ±ndan label mapping'ini oluÅŸtur
        train_file = "data/processed/combined_data.jsonl"
        
        train_data = []
        with open(train_file, "r", encoding="utf-8") as f:
            for line in f:
                train_data.append(json.loads(line))
        
        labels = sorted(list(set([item['label'] for item in train_data])))
        label2id = {label: i for i, label in enumerate(labels)}
        id2label = {i: label for label, i in label2id.items()}
        
        return id2label
    except Exception as e:
        st.error(f"Label mapping yÃ¼klenirken hata oluÅŸtu: {e}")
        # Model eÄŸitimindeki gerÃ§ek label mapping (sorted)
        return {
            0: "abuse_of_dominance",
            1: "anti_competitive_merger", 
            2: "bid_rigging",
            3: "clean",
            4: "customer_sharing",
            5: "exclusive_contracts",
            6: "market_allocation",
            7: "other_competition_violation",
            8: "price_fixing"
        }

def predict_email(subject, body, model, tokenizer, id2label):
    """
    E-posta subject ve body'sini sÄ±nÄ±flandÄ±rÄ±r
    
    Args:
        subject (str): E-posta konusu
        body (str): E-posta iÃ§eriÄŸi
        model: Fine tune edilmiÅŸ model
        tokenizer: Model ile uyumlu tokenizer
        id2label: Label mapping
    
    Returns:
        dict: label ve confidence iÃ§eren sÃ¶zlÃ¼k
    """
    text = subject + " " + body
    
    # Tokenize et ve modelin bulunduÄŸu device'a gÃ¶nder
    inputs = tokenizer(text, return_tensors="pt", truncation=True, max_length=512)
    inputs = {k: v.to(model.device) for k, v in inputs.items()}
    
    model.eval()  # Evaluation moduna al
    with torch.no_grad():
        logits = model(**inputs).logits
        probs = torch.softmax(logits, dim=-1)
        label_id = torch.argmax(probs, dim=-1).item()
        confidence = probs[0, label_id].item()
    
    return {"label": id2label[label_id], "confidence": confidence}

def main():
    st.title("ğŸ“§ E-posta Uyumluluk SÄ±nÄ±flandÄ±rmasÄ±")
    st.markdown("Bu uygulama, e-posta iÃ§eriklerini uyumluluk aÃ§Ä±sÄ±ndan sÄ±nÄ±flandÄ±rÄ±r.")
    
    # Model ve tokenizer'Ä± yÃ¼kle
    model, tokenizer, device = load_model_and_tokenizer()
    id2label = load_label_mapping()
    
    if model is None or tokenizer is None:
        st.stop()
    
    # BaÅŸarÄ±lÄ± yÃ¼kleme mesajÄ±
    st.success(f"âœ… Model baÅŸarÄ±yla yÃ¼klendi ({device})")
    
    # KullanÄ±cÄ± girdileri
    st.header("E-posta Bilgilerini Girin")
    
    col1, col2 = st.columns([1, 1])
    
    with col1:
        subject = st.text_input(
            "ğŸ“ E-posta Konusu (Subject)",
            placeholder="Ã–rn: FiyatlandÄ±rma Ãœzerine GÃ¶rÃ¼ÅŸme Talebi",
            help="E-postanÄ±n konu satÄ±rÄ±nÄ± girin"
        )
    
    with col2:
        body = st.text_area(
            "ğŸ“„ E-posta Ä°Ã§eriÄŸi (Body)",
            placeholder="Ã–rn: Merhaba, yarÄ±n toplantÄ± yapmayÄ± Ã¶neriyorum...",
            help="E-postanÄ±n iÃ§eriÄŸini girin",
            height=100
        )
    
    # Tahmin butonu
    if st.button("ğŸ” SÄ±nÄ±flandÄ±r", use_container_width=True):
        if subject.strip() == "" and body.strip() == "":
            st.warning("âš ï¸ LÃ¼tfen en az konu veya iÃ§erik alanlarÄ±ndan birini doldurun.")
        else:
            try:
                # Tahmin yap
                result = predict_email(subject, body, model, tokenizer, id2label)
                
                # SonuÃ§larÄ± gÃ¶ster
                st.write(f"**SÄ±nÄ±flandÄ±rma:** {result['label']}")
                st.write(f"**GÃ¼ven Skoru:** {result['confidence']:.4f}")
            
            except Exception as e:
                st.error(f"Tahmin yapÄ±lÄ±rken hata oluÅŸtu: {e}")
    

if __name__ == "__main__":
    main()
