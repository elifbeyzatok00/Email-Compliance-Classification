# E-posta Uyumluluk SÄ±nÄ±flandÄ±rmasÄ± (Email Compliance Classification)

Bu proje, e-posta iÃ§eriklerini uyumluluk aÃ§Ä±sÄ±ndan sÄ±nÄ±flandÄ±rmak iÃ§in geliÅŸtirilmiÅŸ bir makine Ã¶ÄŸrenmesi uygulamasÄ±dÄ±r. Ã–zellikle rekabet hukuku ihlalleri ve diÄŸer uyumluluk sorunlarÄ±nÄ± tespit etmek amacÄ±yla tasarlanmÄ±ÅŸtÄ±r.

![Uygulama ArayÃ¼zÃ¼](assets/streamlit%20ui.png)


## ğŸ“‹ Ä°Ã§indekiler

- [Proje HakkÄ±nda](#proje-hakkÄ±nda)
- [Ã–zellikler](#Ã¶zellikler)
- [Kurulum](#kurulum)
- [KullanÄ±m](#kullanÄ±m)
- [Veri YapÄ±sÄ±](#veri-yapÄ±sÄ±)
- [Model DetaylarÄ±](#model-detaylarÄ±)
- [Docker ile Ã‡alÄ±ÅŸtÄ±rma](#docker-ile-Ã§alÄ±ÅŸtÄ±rma)
- [Proje YapÄ±sÄ±](#proje-yapÄ±sÄ±)
- [Gereksinimler](#gereksinimler)
- [KatkÄ±da Bulunma](#katkÄ±da-bulunma)

## ğŸ¯ Proje HakkÄ±nda

Bu sistem, e-posta iÃ§eriklerini aÅŸaÄŸÄ±daki kategorilerde sÄ±nÄ±flandÄ±rÄ±r:

- **abuse_of_dominance**: Pazar gÃ¼cÃ¼nÃ¼n kÃ¶tÃ¼ye kullanÄ±lmasÄ±
- **anti_competitive_merger**: Rekabet karÅŸÄ±tÄ± birleÅŸmeler
- **bid_rigging**: Ä°hale manipÃ¼lasyonu
- **clean**: Temiz/uyumlu iÃ§erik
- **customer_sharing**: MÃ¼ÅŸteri paylaÅŸÄ±mÄ±
- **exclusive_contracts**: MÃ¼nhasÄ±r sÃ¶zleÅŸmeler
- **market_allocation**: Pazar paylaÅŸÄ±mÄ±
- **other_competition_violation**: DiÄŸer rekabet ihlalleri
- **price_fixing**: Fiyat sabitleme

## âœ¨ Ã–zellikler

- ğŸ¤– **Transformer TabanlÄ± Model**: BERT benzeri model kullanarak yÃ¼ksek doÄŸruluk
- ğŸŒ **Web ArayÃ¼zÃ¼**: Streamlit ile kullanÄ±cÄ± dostu arayÃ¼z
- ğŸš€ **GPU DesteÄŸi**: CUDA desteÄŸi ile hÄ±zlÄ± tahmin
- ğŸ“Š **GÃ¼ven Skoru**: Her tahmin iÃ§in gÃ¼venilirlik skoru
- ğŸ³ **Docker DesteÄŸi**: Kolay deployment iÃ§in konteyner desteÄŸi
- ğŸ“„ **PDF Ä°ÅŸleme**: PDF dosyalarÄ±ndan metin Ã§Ä±karma desteÄŸi

## ğŸš€ Kurulum

### Yerel Kurulum

1. **Projeyi klonlayÄ±n:**
```bash
git clone <repository-url>
cd "Email Compliance Classification"
```

2. **Sanal ortam oluÅŸturun:**
```bash
python -m venv new_env
```

3. **Sanal ortamÄ± etkinleÅŸtirin:**
```bash
# Windows
new_env\Scripts\activate

# Linux/Mac
source new_env/bin/activate
```

4. **Gerekli paketleri yÃ¼kleyin:**
```bash
pip install -r requirements.txt
```

5. **UygulamayÄ± Ã§alÄ±ÅŸtÄ±rÄ±n:**
```bash
streamlit run app.py
```

## ğŸ³ Docker ile Ã‡alÄ±ÅŸtÄ±rma

1. **Docker image'Ä±nÄ± oluÅŸturun:**
```bash
docker build -t email-compliance-classifier .
```

2. **Konteyner'Ä± Ã§alÄ±ÅŸtÄ±rÄ±n:**
```bash
docker run -p 8501:8501 email-compliance-app
```

3. **TarayÄ±cÄ±da aÃ§Ä±n:**
```
http://localhost:8501
```

## ğŸ’» KullanÄ±m

### Web ArayÃ¼zÃ¼ ile KullanÄ±m

1. UygulamayÄ± baÅŸlattÄ±ktan sonra web arayÃ¼zÃ¼ne eriÅŸin
2. E-posta konusu (Subject) alanÄ±nÄ± doldurun
3. E-posta iÃ§eriÄŸi (Body) alanÄ±nÄ± doldurun
4. "SÄ±nÄ±flandÄ±r" butonuna tÄ±klayÄ±n
5. SonuÃ§larÄ± gÃ¶rÃ¼ntÃ¼leyin:
   - **SÄ±nÄ±flandÄ±rma**: Tahmin edilen kategori
   - **GÃ¼ven Skoru**: Tahminin gÃ¼venilirlik derecesi (0-1 arasÄ±)

### Programatik KullanÄ±m

```python
from src.app import predict_email, load_model_and_tokenizer, load_label_mapping

# Model ve tokenizer'Ä± yÃ¼kle
model, tokenizer, device = load_model_and_tokenizer()
id2label = load_label_mapping()

# Tahmin yap
subject = "FiyatlandÄ±rma Ãœzerine GÃ¶rÃ¼ÅŸme Talebi"
body = "YarÄ±n toplantÄ± yapmayÄ± Ã¶neriyorum..."

result = predict_email(subject, body, model, tokenizer, id2label)
print(f"SÄ±nÄ±flandÄ±rma: {result['label']}")
print(f"GÃ¼ven Skoru: {result['confidence']:.4f}")
```

## ğŸ“Š Veri YapÄ±sÄ±

### EÄŸitim Verisi
Proje aÅŸaÄŸÄ±daki veri formatlarÄ±nÄ± destekler:

**JSONL formatÄ±:**
```json
{
  "text": "E-posta iÃ§eriÄŸi burada...",
  "label": "clean"
}
```

### Veri DosyalarÄ±

- `data/raw/dataset.jsonl`: Ham EtiketlenmiÅŸ veri seti
- 'data/raw/PDFS': Ham pdf verileri
- `data/processed/dataset_formatted.jsonl`: Ä°ÅŸlenmiÅŸ eÄŸitim verisi (~11,750 Ã¶rnek)
- `data/processed/pdf_dataset.jsonl`: PDF'lerden Ã§Ä±karÄ±lan veriler (~101 Ã¶rnek)
- `data/processed/pdf_dataset_cleaned.jsonl`: PDF'lerden Ã§Ä±karÄ±lan verilerin temizlenmiÅŸ hali
- `data/processed/pdf_dataset_labeled.jsonl`: PDF'lerden Ã§Ä±karÄ±lan temizlenmiÅŸ verilerin etiketlenmiÅŸ hali
- `data/processed/combined_data.jsonl`: BirleÅŸtirilmiÅŸ eÄŸitim verisi

## ğŸ¤– Model DetaylarÄ±

### Model Mimarisi
- **Base Model**: Transformer tabanlÄ± sequence classification modeli
- **Tokenizer**: BERT-compatible tokenizer
- **Max Length**: 512 token
- **Classes**: 9 farklÄ± uyumluluk kategorisi

### EÄŸitilmiÅŸ Modeller
Projede iki farklÄ± eÄŸitilmiÅŸ model bulunur:

1. **trained_model1**: 
   - `checkpoint-2350`
   - `checkpoint-3525`

2. **trained_model2**: 
   - `checkpoint-3000`
   - `checkpoint-3111` (varsayÄ±lan olarak kullanÄ±lan)

### Model PerformansÄ±
- GPU desteÄŸi ile hÄ±zlÄ± tahmin
- GÃ¼ven skoru ile tahmin gÃ¼venilirliÄŸi
- Real-time sÄ±nÄ±flandÄ±rma

## ğŸ“ Proje YapÄ±sÄ±

```
Email Compliance Classification/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/
â”‚   â”‚   â”œâ”€â”€ dataset.jsonl              # Ham veri seti
â”‚   â”‚   â””â”€â”€ PDFs/                      # PDF dosyalarÄ± (100 adet)
â”‚   â””â”€â”€ processed/
â”‚       â”œâ”€â”€ dataset_formatted.jsonl    # Ä°ÅŸlenmiÅŸ veri
â”‚       â”œâ”€â”€ pdf_dataset.jsonl         # PDF'lerden Ã§Ä±karÄ±lan veri
â”‚       â”œâ”€â”€ pdf_dataset_cleaned.jsonl         
â”‚       â”œâ”€â”€ pdf_dataset_labeled.jsonl         
â”‚       â””â”€â”€ combined_data.jsonl       # BirleÅŸtirilmiÅŸ veri
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ trained_model1/               # Ä°lk eÄŸitilmiÅŸ model
â”‚   â””â”€â”€ trained_model2/               # Ä°kinci eÄŸitilmiÅŸ model (aktif)
â”œâ”€â”€ notebooks/
â”‚   â””â”€â”€ main.ipynb                    # Veri iÅŸleme ve model eÄŸitimi
â”œâ”€â”€ new_env/                          # Python sanal ortamÄ±
â”œâ”€â”€ app.py                            # Streamlit uygulamasÄ± (ana dizin)
â”œâ”€â”€ Dockerfile                        # Docker konfigÃ¼rasyonu
â”œâ”€â”€ requirements.txt                  # TÃ¼m proje baÄŸÄ±mlÄ±lÄ±klarÄ±
â”œâ”€â”€ requirements-docker.txt           # Docker iÃ§in optimize edilmiÅŸ baÄŸÄ±mlÄ±lÄ±klar
â”œâ”€â”€ assets                            # README'de kullanÄ±lan resim ve video
â”‚   â”œâ”€â”€ streamlit ui.png              # UygulamanÄ±n Streamlit UI GÃ¶rseli
â”‚   â””â”€â”€ proje nasÄ±l Ã§alÄ±ÅŸÄ±r.mp4       # Proje nasÄ±l Ã§alÄ±ÅŸÄ±r videosu
â””â”€â”€ README.md                         # Bu dosya
```

## ğŸ“¦ Gereksinimler

### Ana BaÄŸÄ±mlÄ±lÄ±klar
- **Python**: 3.11+
- **PyTorch**: 2.8.0+ (CUDA desteÄŸi ile)
- **Transformers**: 4.56.1
- **Streamlit**: 1.49.1
- **NumPy**: 2.2.6
- **Pandas**: 2.3.2

### Tam BaÄŸÄ±mlÄ±lÄ±k Listesi
DetaylÄ± baÄŸÄ±mlÄ±lÄ±k listesi iÃ§in `requirements.txt` dosyasÄ±na bakÄ±nÄ±z.

## ğŸ”§ YapÄ±landÄ±rma

### Model Yolu
VarsayÄ±lan model yolu: `models/trained_model2/checkpoint-3111`

FarklÄ± bir model kullanmak iÃ§in `app.py` dosyasÄ±nda `model_path` deÄŸiÅŸkenini gÃ¼ncelleyin:

```python
model_path = "models/trained_model1/checkpoint-3525"  # Ã–rnek
```

### GPU KullanÄ±mÄ±
Uygulama otomatik olarak GPU'yu algÄ±lar ve kullanÄ±r. GPU mevcut deÄŸilse CPU'da Ã§alÄ±ÅŸÄ±r.

## ğŸš¨ Ã–nemli Notlar

1. **Model DosyalarÄ±**: Model dosyalarÄ± bÃ¼yÃ¼k olduÄŸu iÃ§in Git LFS kullanÄ±lmasÄ± Ã¶nerilir
2. **Bellek KullanÄ±mÄ±**: Modeller yaklaÅŸÄ±k 500MB RAM kullanÄ±r
3. **GPU Gereksinimleri**: CUDA uyumlu GPU Ã¶nerilir (opsiyonel)
4. **Veri GizliliÄŸi**: Hassas verilerle Ã§alÄ±ÅŸÄ±rken gÃ¼venlik Ã¶nlemlerini alÄ±n

## ğŸ¤ KatkÄ±da Bulunma

1. Fork yapÄ±n
2. Feature branch oluÅŸturun (`git checkout -b feature/yeni-ozellik`)
3. DeÄŸiÅŸikliklerinizi commit edin (`git commit -m 'Yeni Ã¶zellik eklendi'`)
4. Branch'inizi push edin (`git push origin feature/yeni-ozellik`)
5. Pull Request oluÅŸturun


